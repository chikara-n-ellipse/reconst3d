{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imsup3d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-lx-UAtCxl1mYa8CY1zis88wjCQac0xt",
      "authorship_tag": "ABX9TyM2FlTt2yce5/YeRrjbrYT5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chikara-n-ellipse/reconst3d/blob/feature%2Fsimple-gan/imsup3d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzH7QXCENn2M"
      },
      "source": [
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as tfs\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "# %matplotlib notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wATBd12d_d5w"
      },
      "source": [
        "extract_dir = \"/content/img_cropped_celeba\"\n",
        "shutil.unpack_archive(\n",
        "    \"/content/drive/MyDrive/Projects/celebA/img_cropped_celeba.zip\", \n",
        "    extract_dir=extract_dir,\n",
        "    )\n",
        "data_dir = \"/content/img_cropped_celeba/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy3p7o3Sidp0"
      },
      "source": [
        "# !ls /content/img_cropped_celeba/val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqeLHkFNR8l8"
      },
      "source": [
        "# Setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMBUvTkAd7OY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiB2E5yY_kbN"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  \"\"\"\n",
        "    Vanilla GAN Generator\n",
        "  \"\"\"\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "\n",
        "    # First upsampling\n",
        "    self.ct0_0 = nn.ConvTranspose2d(64, 48, 3)\n",
        "    self.ct0_1 = nn.ConvTranspose2d(48, 32, 3)\n",
        "    self.lrelu0 = nn.LeakyReLU(0.25)\n",
        "\n",
        "    # Second upsampling\n",
        "    self.upsample1 = nn.Upsample((8, 8))\n",
        "    self.c1_0 = nn.Conv2d(32, 24, 3)\n",
        "    self.c1_1 = nn.Conv2d(24, 16, 3)\n",
        "    self.lrelu1 = nn.LeakyReLU(0.25)\n",
        "\n",
        "    # Third upsampling\n",
        "    self.upsample2 = nn.Upsample((16, 16))\n",
        "    self.c2_0 = nn.Conv2d(16, 8, 3, padding='same')\n",
        "    self.c2_1 = nn.Conv2d(8, 3, 3, padding='same')\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.ct0_0(x)\n",
        "    x = self.ct0_1(x)\n",
        "    x =  self.lrelu0(x)\n",
        "\n",
        "    x = self.upsample1(x)\n",
        "    x = self.c1_0(x)\n",
        "    x = self.c1_1(x)\n",
        "    x =  self.lrelu1(x)\n",
        "\n",
        "    x = self.upsample2(x)\n",
        "    x = self.c2_0(x)\n",
        "    x = self.c2_1(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  \"\"\"\n",
        "    Vanilla GAN Discriminator\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    # First downsampling\n",
        "    self.c0_0 = nn.Conv2d(3, 8, 3)\n",
        "    self.c0_1 = nn.Conv2d(8, 16, 3)\n",
        "    self.lrelu0 = nn.LeakyReLU(0.25)\n",
        "    self.downsample0 = nn.Upsample((8, 8))\n",
        "\n",
        "    # Second downsampling\n",
        "    self.c1_0 = nn.Conv2d(16, 24, 3)\n",
        "    self.c1_1 = nn.Conv2d(24, 32, 3)\n",
        "    self.lrelu1 = nn.LeakyReLU(0.25)\n",
        "    self.downsample1 = nn.Upsample((6, 6))\n",
        "\n",
        "    # Third downsampling\n",
        "    self.c2_0 = nn.Conv2d(32, 48, 4)\n",
        "    self.c2_1 = nn.Conv2d(48, 64, 3)\n",
        "    self.linear = nn.Linear(64, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.c0_0(x)\n",
        "    x = self.c0_1(x)\n",
        "    x = self.lrelu0(x)\n",
        "    x =  self.downsample0(x)\n",
        "\n",
        "    x = self.c1_0(x)\n",
        "    x = self.c1_1(x)\n",
        "    x = self.lrelu1(x)\n",
        "    x =  self.downsample1(x)\n",
        "\n",
        "    x = self.c2_0(x)\n",
        "    x = self.c2_1(x)\n",
        "    x = self.linear(x.squeeze())\n",
        "    x = self.sigmoid(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgTDvDyvt9p2"
      },
      "source": [
        "def fix_seed(seed):\n",
        "    # random\n",
        "    # random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transform\n",
        "        \n",
        "    def get_class_label(self, image_name):\n",
        "        # your method here\n",
        "        y = ...\n",
        "        return y\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        x = torch.tensor(plt.imread(image_path))/255.0\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x.permute(2, 0, 1))\n",
        "        return x\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "fix_seed(0)\n",
        "batch_size = 512\n",
        "\n",
        "paths = [data_dir+'train'+'/'+fname for fname in os.listdir(data_dir+'train')]\n",
        "p_depth = 4\n",
        "transform = tfs.Resize(2**p_depth)\n",
        "dataset = ImageDataset(paths, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size,\n",
        "                        shuffle=True, num_workers=0)\n",
        "\n",
        "\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "optimizer_gen = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "optimizer_dis = torch.optim.Adam(discriminator.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "        turn_steps = {'dis':10, 'gen':10}, \n",
        "        max_step = None, \n",
        "        is_debug = False, \n",
        "        show_interval = 100\n",
        "        ):\n",
        "    for i_batch, sample_batched in enumerate(dataloader):\n",
        "\n",
        "        if i_batch % (turn_steps['dis']+turn_steps['gen']) < turn_steps['dis']:\n",
        "            step_turn = 'dis'\n",
        "        else:\n",
        "            step_turn = 'gen'\n",
        "\n",
        "        if max_step is not None and i_batch >= max_step:\n",
        "            break\n",
        "        if is_debug:\n",
        "            print(i_batch, sample_batched.size())\n",
        "            plt.imshow(torch.cat(list(sample_batched.permute(0, 2, 3, 1)[:3]), 1))\n",
        "            plt.show()\n",
        "            # input()\n",
        "        \n",
        "        generator.train()\n",
        "        discriminator.train()\n",
        "        optimizer_gen.zero_grad()\n",
        "        optimizer_dis.zero_grad()\n",
        "\n",
        "        image_real = sample_batched.to(device)\n",
        "        z = torch.randn((batch_size, 64, 1, 1)).to(device)\n",
        "\n",
        "        image_fake = generator(z)\n",
        "\n",
        "        # print(image_fake[0])\n",
        "        # input()\n",
        "        \n",
        "        if step_turn == 'dis':\n",
        "\n",
        "            p_real = discriminator(image_real)\n",
        "            p_fake = discriminator(image_fake)\n",
        "\n",
        "            loss_dis_real = - torch.log(p_real).mean()\n",
        "            loss_dis_fake = - torch.log(1 - p_fake).mean()\n",
        "            loss_dis = loss_dis_real + loss_dis_fake\n",
        "\n",
        "            loss_dis.backward()\n",
        "            optimizer_dis.step()\n",
        "\n",
        "        elif step_turn == 'gen':\n",
        "\n",
        "            p_fake = discriminator(image_fake)\n",
        "\n",
        "            loss_gen = - torch.log(p_fake).mean()\n",
        "            \n",
        "            loss_gen.backward()\n",
        "            optimizer_gen.step()\n",
        "\n",
        "        if i_batch % show_interval == 0:\n",
        "            if step_turn == 'dis':\n",
        "                print(f\"p_fake:{p_fake.detach().cpu().mean().item():.3f}, p_real:{p_real.detach().cpu().mean().item():.3f}\")\n",
        "            elif step_turn == 'gen':\n",
        "                print(f\"p_fake:{p_fake.detach().mean().item():.3f}\")\n",
        "            print(image_fake.size())\n",
        "            plt.imshow(torch.cat(list(image_fake.detach().cpu().permute(0, 2, 3, 1)[:3]), 1))\n",
        "            plt.show()\n",
        "\n",
        "for epoch in range(100000):\n",
        "    print(f\"epoch: {epoch:05}\")\n",
        "    train_one_epoch(turn_steps={'dis':10, 'gen':10}, show_interval=100000000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y3lI9RLSnAO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYlaoZVCSm87"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqFCYqaySm6v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbojION2_kNs"
      },
      "source": [
        "config = {\n",
        "    'batchsize': 2,\n",
        "    'num_workers':4,\n",
        "    'image_size': 64,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgMBoclM_kP4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLtIRZMw_kSK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E6-YDuZ_kUd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkhQhnad_kWr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsi5H0l6_kYz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5xxEai0_kdf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvvReEnM_kf5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZREkS-i_kiW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "livigcVM-Z9U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}